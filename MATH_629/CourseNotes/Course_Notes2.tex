\documentclass{article}
\usepackage{amsmath, amsfonts}
\usepackage{enumerate}
\usepackage{subfig}
\input{notes_macros}
\setlength\parindent{0pt}
\setlength{\parskip}{\baselineskip}%
\begin{document}
\CPT{2}

\idf{2.1} \textbf{Kaplan-Meirer Survival Curves } also known as \textbf{ product limit estimators }, are non-parametric estimates of survival curves. They are step functions with ``steps'' at event times in the sample data.
\NTS \, Draw step functions with steps at events times.

\ir{2.1} Recall,

\[
S(t) = P(T>t)
\]

There is no censoring in group 2 (placebo group). Thus, it is straightforward to estimate a survival curve. This straightforward estimation will be the same as the Kaplan-Meirer estimate. For group 2, deriving the Kaplan-Meirer estimate will be more involved. For group 2, (or any uncensored data) we just use the formula
\[
\hat{S}(t_{(f)}) = \frac{\# \text{surviving past} \, t_{(f)}}{n}
\]
where $n$ is the number of observations.

\ir{2.2} Recall the formula that for any two events, $A$ and $B$ we have
\[
P(A \cap B) = P(A|B)P(B)
\]
We have $S(0) = S(t_{(1)}) = 1$.
Now let $t_{f}>0$.
\begin{align*}
S(t_{(f)}) & = P(T > t_{(f)}) = P(T>t_{(f)} \cap T \ge t_{(f)}) \\
& = P(T>t_{(f)} | T \ge t_{(f)}) P(T \ge t_{(f)}) = P(T>t_{(f)} | T \ge t_{(f)}) P(T > t_{(f-1)})  \\
& = P(T>t_{(f)} | T \ge t_{(f)}) S(t_{(f-1)})
\end{align*}
Thus, for $t_{f}>0$ we find estimate  $\hat{S}(t_{(f)})$, recursively, using remark 1.2, as
\[
 \hat{S}(t_{(f)}) = \widehat{P(T>t_{(f)} | T \ge t_{(f)})} \hat{S}(t_{(f-1)}) = \Pi_{i=1}^f \hat{P(T>t_{(i)}|T \ge t_{(i)})}
 \]
This is known as the  \textbf{Kaplan-Meirer} or \textbf{ product limit estimator } of the survival curve.

\prbm{2.1}
\begin{align*}
&\hat{S}(0)=1 \\
&\hat{S}(6)=\hat{P(T>6)|T \ge 6)} \hat{S}(0) = (18/21)*1 \approx 0.8571 \\
&\hat{S}(7)=\hat{P(T>7)|T \ge 7)} \hat{S}(6) = (16/17)*(18/21) = (96/119) \approx 0.8067 \\
&\hat{S}(10)=\hat{P(T>10)|T \ge 10)} \hat{S}(7) = (14/15)*(96/119) = (64/85) \approx 0.7529 \\
&\hat{S}(13)=\hat{P(T>13)|T \ge 13)} \hat{S}(10) = (11/12)*(64/85) = (176/255) \approx 0.6902 \\
&\hat{S}(16)= \hat{P(T>16)|T \ge 16)} \hat{S}(13) = (10/11)*(176/255) = (32/51) \approx 0.6275 \\
&\hat{S}(22)= \hat{P(T>22)|T \ge 22)} \hat{S}(16) = (6/7)*(32/51) = (64/119) \approx 0.5378 \\
&\hat{S}(23)= \hat{P(T>23)|T \ge 23)} \hat{S}(22) = (5/6)*(64/119) = (160/357) \approx 0.4482 \
\end{align*}

\prbm{2.2}
Open Remission\_make and MATH629\_code.R and follow the steps.

\ir{2.3}

\begin{enumerate}
\item If we have two large samples from two quantitative populations we can test whether the difference between the sample means is statistically significant. In that case, we can reject the null hypothesis that the population means are the same. Use the statistic
\[
\frac{\bar{x}_1 - \bar{x}_2}{\sqrt{s_1^2/n_1 + s_2^2/n_2}} \sim t(n_1+n_2-2)
\]
\item If we have large samples from two qualitative populations we can test whether levels of categorical variables are significantly dependent. We use the statistic
\[
  \sum_{j=1}^b \sum_{i=1}^a \frac{(X_{ij}-E_{ij})^2}{E_{ij}} \sim \chi^2((b-1)(a-1))
  \]
\item We can test whether the survival experiences of two group are statistically different using a chi-squared test. This is known as a \textbf{log-rank test}.
\end{enumerate}

\ir{2.4} If the survival experiences are the same, for all $f$, for both groups, you expect the proportion of failures to be approximately the observed number of failures. That is, you expect,
\[
m_{if} \approx e_{if}
\]
for $i=1,2$ and all $f$.
Our LRS is
\[
\text{LRS} = LRS = \frac{(O_i - E_i)^2}{\text{Var}(O_i-E_i)} = \frac{(10.26)^2}{6.285} = 16.793
\]
Since, $\chi^2_{0.05} = 3.841$ and $16.793>3.841$ we reject $H_0$. Alternatively,
p-value = $P(X > 16.793) =  0.000042.$ where $X \sim \chi^2(1)$. Thus, we reject $H_0$ for any $\alpha>0.000042.$.
Note the approximate LRS is
\[
LRS = \frac{(O_1 - E_1)^2}{E_1} + \frac{(O_2 - E_2)^2}{E_2} = (-10.26)^2/19.26 + (10.26)^2/10.74 = 15.276
\]
which has p-value = $P(X > 15.276) =  .000093.$ where $X \sim \chi^2(1)$. Thus, we reject $H_0$ for any $\alpha>.000093.$ using this statistic.

\ir{2.5}
The weights you choose depend in which part of the survival study you are most interested in examining differences in the survival experiences.

\prbm{2.5}
\begin{center}
\begin{tabular}{ c c c c c c c c}
\multicolumn{2}{c}{\textbf{Strata 1}} & \multicolumn{2}{c}{\# failures} & \multicolumn{2}{c}{\# risk set} & \multicolumn{2}{c}{\# expected} \\
 $t_{f}$ & & $m_{1f}$ & $m_{2f}$ & $n_{1f}$ & $n_{2f}$ & $e_{1f}$ & $e_{2f}$ \\ \hline
0 & & 0 & 0  & 7 & 4 & 0 & 0 \\
11 & & 0 & 1 & 7 & 4 & 7/11 & 4/11 \\
12 & & 0 & 1 & 7 & 3 & 7/10 & 3/10 \\
15 & & 0 & 1 & 7 & 2 & 7/9 & 2/9 \\
23 & & 0 & 1 & 4 & 1 & 4/5 & 1/5 \\ \hline
 &&  $m_{1 \cdot 1}=0$&$m_{2 \cdot 1}=4$ & & & $e_{1 \cdot 1} = 2.914$ & $e_{2 \cdot 1}=1.086$
\end{tabular}
\end{center}

\ir{2.6}
A problem with the stratified log rank test is you might get few observations in each strata. This might affect the validity of your test because using a Chi squared test depends on a large sample. Note you can do weighted stratified log rank tests. You can account for confounding in a semi-parametric or parametric model instead by including the confounder in the model - we will see this next chapter.

\prbm{2.6}
$\alpha=.05$ and $z_{\alpha/2}=1.96$. \\

CI for 6 weeks: $0.857 \pm 1.96 \sqrt{(.857)^2(0.0079)}$ which gives $(.708,1.006)$ or $(.708,1)$. \\

For 7 weeks:
\[ \frac{m_2}{m_2(n_2-m_2)} = 0.0037
\]
$\hat{S}_{KM}(7) = (0.807)^2(0.0079+0.0037)=(0.807)^2(0.016) = 0.0076 $. \\
CI for 7 weeks: $0.807 \pm 1.96 \sqrt{0.0076}$ which gives $(0.6361, 0.9779)$.

\ir{2.7}
In the book they use the inequality
\[
(\hat{S}_{KM}(t) - 0.5)^2 < \chi^2_{1,\alpha}\hat{var}[\hat{S}_{KM}(M)]
\]
instead. \\
It doesn't always work as the interval might contain 0 and might not have an upper bound.
A crude way to compare survival experiences is to compare estimated medians. If the CI overlap you might say (very roughly) that the survival experiences are the same.
\end{document}

